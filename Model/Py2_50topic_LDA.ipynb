{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim, os, pickle\n",
    "import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### take some data\n",
    "df_train = pd.read_csv('../../../../Data/Raw/train_clean.csv',encoding='utf-8')\n",
    "qid_stack = df_train['qid1'].append(df_train['qid2'])\n",
    "df_train_naExc = df_train[~df_train.isnull().any(axis=1)]\n",
    "df_buf1 = df_train_naExc[['qid1','question1']]\n",
    "df_buf2 = df_train_naExc[['qid2','question2']]\n",
    "df_buf1.columns = ['qid','question']\n",
    "df_buf2.columns = ['qid','question']\n",
    "df_stack = df_buf1.append(df_buf2)\n",
    "df_stack_dupExc = df_stack.drop_duplicates()\n",
    "test_buf = df_stack_dupExc['question']#.head(1000)#.iloc[5000:7000]#head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file = open('LDA_pickle_New_20170520_50topic_ldamodel_test_traing.pkl', 'rb')\n",
    "ldamodel_dump = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "pkl_file1 = open('Py2_dictionary.pkl', 'rb')\n",
    "dictionary = pickle.load(pkl_file1)\n",
    "pkl_file.close()\n",
    "#print(ldamodel_dump.keys())\n",
    "##### for predict \n",
    "#ldamodel = ldamodel_dump['lda_model']\n",
    "#dictionary = ldamodel_dump['dictionary']\n",
    "##### for build the lda-model by yourself \n",
    "#corpus = ldamodel_dump['encoding_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# some tools\n",
    "######### Tokenize the corpus\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "def tokenize_doc(new_corpus):\n",
    "    new_corpus\n",
    "    texts = []\n",
    "    ###\n",
    "    ### Progressing bar setting\n",
    "    totall_size = len(new_corpus)\n",
    "    counter = 0\n",
    "    progress = 0\n",
    "    # loop through document list\n",
    "    for i in new_corpus:    \n",
    "#         ### Monitor the progress\n",
    "#         if progress%(1000) ==0:\n",
    "#             bar = \"[\" + int(progress/1000)*\"|\"+\">\"+ (10-int(progress/1000))*\"-\" + str((progress/100)) + \"%\" \"]\"\n",
    "#             print(bar)\n",
    "#         #### count\n",
    "#         counter += 1\n",
    "#         progress = int(10000*(counter/totall_size))\n",
    "\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        \n",
    "        # stem tokens\n",
    "#         stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        stemmed_tokens = []\n",
    "        for i in stopped_tokens:\n",
    "            try:\n",
    "                stemmed_tokens = stemmed_tokens + [p_stemmer.stem(i)]\n",
    "            except:\n",
    "                print(i)\n",
    "        # add tokens to list            \n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "######  predict the topic\n",
    "def topic_predict(new_corpus, model, dictionary):\n",
    "    tokenize_buf = tokenize_doc([new_corpus])\n",
    "    doc_bow = [dictionary.doc2bow(text) for text in tokenize_buf]\n",
    "    que_vec = [item for itemList in doc_bow for item in itemList]\n",
    "    topic_vec = model[que_vec]\n",
    "\n",
    "    word_count_array = np.empty((len(topic_vec), 2), dtype = np.object)\n",
    "    for i in range(len(topic_vec)):\n",
    "        word_count_array[i, 0] = topic_vec[i][0]\n",
    "        word_count_array[i, 1] = topic_vec[i][1]\n",
    "\n",
    "    idx = np.argsort(word_count_array[:, 1])\n",
    "    idx = idx[::-1]\n",
    "    word_count_array = word_count_array[idx]\n",
    "\n",
    "    final = []\n",
    "    final = model.print_topic(word_count_array[0, 0], len(word_count_array))#model.print_topic(20, 20)# model.print_topic(word_count_array[0, 0], len(word_count_array)) # model.print_topic(word_count_array[0, 0], len(word_count_array))#1)\n",
    "\n",
    "    question_topic = final.split('*') ## as format is like \"probability * topic\"\n",
    "    return question_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19, u'0.277*\"india\" + 0.074*\"countri\" + 0.022*\"s\" + 0.022*\"educ\"'), (25, u'0.114*\"job\" + 0.101*\"univers\" + 0.070*\"look\" + 0.044*\"major\"'), (38, u'0.067*\"servic\" + 0.049*\"can\" + 0.045*\"exist\" + 0.040*\"idea\"'), (11, u'0.158*\"quora\" + 0.105*\"question\" + 0.058*\"answer\" + 0.031*\"anim\"'), (3, u'0.305*\"use\" + 0.068*\"word\" + 0.039*\"can\" + 0.035*\"sentenc\"'), (39, u'0.066*\"day\" + 0.057*\"1\" + 0.049*\"3\" + 0.049*\"5\"'), (34, u'0.054*\"man\" + 0.039*\"choos\" + 0.037*\"purpos\" + 0.035*\"girlfriend\"'), (20, u'0.127*\"t\" + 0.065*\"want\" + 0.053*\"feel\" + 0.051*\"love\"'), (31, u'0.072*\"sex\" + 0.063*\"data\" + 0.038*\"law\" + 0.035*\"big\"'), (6, u'0.097*\"live\" + 0.092*\"us\" + 0.036*\"usa\" + 0.033*\"parent\"')]\n"
     ]
    }
   ],
   "source": [
    "###### check the topic stack\n",
    "print(ldamodel_dump.print_topics(num_topics=10, num_words=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the story of Kohinoor (Koh-i-Noor) Diamond \n",
      "[u'0.058', u'\"car\" + 0.034', u'\"interview\"']\n"
     ]
    }
   ],
   "source": [
    "###### Predict a topic\n",
    "pivot = 1\n",
    "print(test_buf.iloc[pivot])\n",
    "print(topic_predict(test_buf.iloc[pivot], ldamodel_dump, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Question:\n",
      "Will there really be any war between India and Pakistan over the Uri attack  What will be its effects \n",
      "\n",
      "[u'0.047', u'\"trump\" + 0.047', u'\"2016\" + 0.045', u'\"come\" + 0.043', u'\"product\" + 0.039', u'\"will\" + 0.037', u'\"win\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "What is the easiest way to become a billionaire($) \n",
      "\n",
      "[u'0.221', u'\"make\" + 0.139', u'\"much\" + 0.128', u'\"money\" + 0.061', u'\"can\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "How can we acquire a positive morality \n",
      "\n",
      "[u'0.052', u'\"call\" + 0.044', u'\"follow\" + 0.040', u'\"instagram\" + 0.037', u'\"can\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "Why do dreams look so real \n",
      "\n",
      "[u'0.200', u'\"mean\" + 0.094', u'\"say\" + 0.046', u'\"die\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "What makes a programmer \"good \"\n",
      "\n",
      "[u'0.052', u'\"call\" + 0.044', u'\"follow\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "What should I do for Web design \n",
      "\n",
      "[u'0.070', u'\"account\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "What is the difference between a turkey and a chicken \n",
      "\n",
      "[u'0.053', u'\"cultur\" + 0.040', u'\"differ\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "What is the benefit of going Walking every morning \n",
      "\n",
      "[u'0.170', u'\"time\" + 0.111', u'\"book\" + 0.092', u'\"possibl\" + 0.056', u'\"travel\" + 0.055', u'\"read\"']\n",
      "==========================================================================================\n",
      "Question:\n",
      "Prove that SNR of power = (SNR of voltage) sequare \n",
      "\n",
      "[u'0.069', u'\"free\" + 0.057', u'\"game\" + 0.055', u'\"play\"']\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "###### Predict a topic\n",
    "print(\"=\"*90)\n",
    "for i in range(100,1000,100):\n",
    "    pivot = i\n",
    "    print(\"Question:\\n\"+test_buf.iloc[pivot]+\"\\n\")\n",
    "    print(topic_predict(test_buf.iloc[pivot], ldamodel_dump, dictionary))\n",
    "    print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
