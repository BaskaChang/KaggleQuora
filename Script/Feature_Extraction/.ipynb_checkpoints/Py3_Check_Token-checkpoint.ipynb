{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim,os, re\n",
    "import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########\n",
    "######### Tokenize the doc\n",
    "#########\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "############\n",
    "def tokenize_doc(new_corpus):\n",
    "    new_corpus\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in new_corpus:    \n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        \n",
    "        # stem tokens\n",
    "#         stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        stemmed_tokens = []\n",
    "        for i in stopped_tokens:\n",
    "            try:\n",
    "                stemmed_tokens = stemmed_tokens + [p_stemmer.stem(i)]\n",
    "            except:\n",
    "                print(i)\n",
    "                stemmed_tokens = stemmed_tokens + [i]\n",
    "        # add tokens to list            \n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "######\n",
    "######  predict the topic\n",
    "######\n",
    "def topic_predict(new_corpus, model, dictionary):\n",
    "    tokenize_buf = tokenize_doc([new_corpus])\n",
    "    doc_bow = [dictionary.doc2bow(text) for text in tokenize_buf]\n",
    "    que_vec = [item for itemList in doc_bow for item in itemList]\n",
    "    topic_vec = ldamodel[que_vec]\n",
    "\n",
    "    word_count_array = np.empty((len(topic_vec), 2), dtype = np.object)\n",
    "    for i in range(len(topic_vec)):\n",
    "        word_count_array[i, 0] = topic_vec[i][0]\n",
    "        word_count_array[i, 1] = topic_vec[i][1]\n",
    "\n",
    "    idx = np.argsort(word_count_array[:, 1])\n",
    "    idx = idx[::-1]\n",
    "    word_count_array = word_count_array[idx]\n",
    "\n",
    "    final = []\n",
    "    final = ldamodel.print_topic(word_count_array[0, 0], len(word_count_array))#1)\n",
    "\n",
    "    question_topic = final.split('*') ## as format is like \"probability * topic\"\n",
    "    return question_topic\n",
    "    #return question_topic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = os.getcwd()+\"/../../../../../Data/token_test_train_all.csv\"\n",
    "pkl_file = open(file_name, 'rb')\n",
    "check_piece = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_df', 'tokenize_data'])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_piece.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5229451\n",
      "5229451\n"
     ]
    }
   ],
   "source": [
    "print(str(len(check_piece['data_df'])))\n",
    "print(str(len(check_piece['tokenize_data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>data_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Why am I mentally very lonely  How can I solve...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           question data_set\n",
       "0    1  What is the step by step guide to invest in sh...    train\n",
       "1    3  What is the story of Kohinoor (Koh-i-Noor) Dia...    train\n",
       "2    5  How can I increase the speed of my internet co...    train\n",
       "3    7  Why am I mentally very lonely  How can I solve...    train\n",
       "4    9  Which one dissolve in water quikly sugar, salt...    train"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_piece['data_df'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>data_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>What is the most study scene in twin peaks</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>How question FedEx packages delivered</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>Can a non-alcoholic restaurant be a huge success</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>What are the best and worst things examination...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>How do I out get rid of Erectile Dysfunction</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid                                           question data_set\n",
       "2345791  2345791        What is the most study scene in twin peaks      test\n",
       "2345792  2345792             How question FedEx packages delivered      test\n",
       "2345793  2345793  Can a non-alcoholic restaurant be a huge success      test\n",
       "2345794  2345794  What are the best and worst things examination...     test\n",
       "2345795  2345795      How do I out get rid of Erectile Dysfunction      test"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_piece['data_df'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['step', 'step', 'guid', 'invest', 'share', 'market', 'india'],\n",
       " ['stori', 'kohinoor', 'koh', 'noor', 'diamond'],\n",
       " ['can', 'increas', 'speed', 'internet', 'connect', 'use', 'vpn'],\n",
       " ['mental', 'lone', 'can', 'solv'],\n",
       " ['one',\n",
       "  'dissolv',\n",
       "  'water',\n",
       "  'quikli',\n",
       "  'sugar',\n",
       "  'salt',\n",
       "  'methan',\n",
       "  'carbon',\n",
       "  'di',\n",
       "  'oxid']]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_piece['tokenize_data'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['studi', 'scene', 'twin', 'peak'],\n",
       " ['question', 'fedex', 'packag', 'deliv'],\n",
       " ['can', 'non', 'alcohol', 'restaur', 'huge', 'success'],\n",
       " ['best',\n",
       "  'worst',\n",
       "  'thing',\n",
       "  'examin',\n",
       "  'public',\n",
       "  'transit',\n",
       "  'visakhapatnam',\n",
       "  'andhra',\n",
       "  'pradesh',\n",
       "  'india',\n",
       "  'improv'],\n",
       " ['get', 'rid', 'erectil', 'dysfunct']]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indFrom = len(check_piece['tokenize_data'])\n",
    "check_piece['tokenize_data'][(indFrom-5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
