{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim,os\n",
    "import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../Data/train_clean.csv',encoding='utf-8')\n",
    "df_test = pd.read_csv('../../Data/test_clean.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "qid_stack = df_train['qid1'].append(df_train['qid2'])\n",
    "df_train_naExc = df_train[~df_train.isnull().any(axis=1)]\n",
    "df_buf1 = df_train_naExc[['qid1','question1']]\n",
    "df_buf2 = df_train_naExc[['qid2','question2']]\n",
    "df_buf1.columns = ['qid','question']\n",
    "df_buf2.columns = ['qid','question']\n",
    "df_stack = df_buf1.append(df_buf2)\n",
    "df_stack_dupExc = df_stack.drop_duplicates()\n",
    "df_stack_dupExc['data_set'] = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537931\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>data_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Why am I mentally very lonely  How can I solve...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           question data_set\n",
       "0    1  What is the step by step guide to invest in sh...    train\n",
       "1    3  What is the story of Kohinoor (Koh-i-Noor) Dia...    train\n",
       "2    5  How can I increase the speed of my internet co...    train\n",
       "3    7  Why am I mentally very lonely  How can I solve...    train\n",
       "4    9  Which one dissolve in water quikly sugar, salt...    train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_stack_dupExc))\n",
    "df_stack_dupExc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "qid_stack = df_test['test_id']\n",
    "df_train_naExc = df_test[~df_test.isnull().any(axis=1)]\n",
    "df_buf1 = df_train_naExc[['test_id','question1']]\n",
    "df_buf2 = df_train_naExc[['test_id','question2']]\n",
    "df_buf1.columns = ['qid','question']\n",
    "df_buf2.columns = ['qid','question']\n",
    "df_stack = df_buf1.append(df_buf2)\n",
    "df_stack_dupExc2 = df_stack.drop_duplicates()\n",
    "df_stack_dupExc2['data_set'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4691520\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>data_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24  How...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           question data_set\n",
       "0    0  How does the Surface Pro himself 4 compare wit...     test\n",
       "1    1  Should I have a hair transplant at age 24  How...     test\n",
       "2    2  What but is the best way to send money from Ch...     test\n",
       "3    3                        Which food not emulsifiers      test\n",
       "4    4                   How \"aberystwyth\" start reading      test"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_stack_dupExc2))\n",
    "df_stack_dupExc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFrame_buf = df_stack_dupExc.append(df_stack_dupExc2)\n",
    "test_buf = dataFrame_buf['question']#.head(1000)#.iloc[5000:7000]#head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229451"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile sample documents into a list\n",
    "# doc_buf = df_stack_dupExc['question']\n",
    "# doc_buf = doc_buf.tolist()\n",
    "# doc_set = doc_buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########\n",
    "######### Tokenize the doc\n",
    "#########\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "############\n",
    "def tokenize_doc(new_corpus):\n",
    "    new_corpus\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in new_corpus:    \n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        \n",
    "        # stem tokens\n",
    "#         stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        stemmed_tokens = []\n",
    "        for i in stopped_tokens:\n",
    "            try:\n",
    "                stemmed_tokens = stemmed_tokens + [p_stemmer.stem(i)]\n",
    "            except:\n",
    "                print(i)\n",
    "                stemmed_tokens = stemmed_tokens + [i]\n",
    "        # add tokens to list            \n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "# ######\n",
    "# ######  predict the topic\n",
    "# ######\n",
    "# def topic_predict(new_corpus, model, dictionary):\n",
    "#     tokenize_buf = tokenize_doc([new_corpus])\n",
    "#     doc_bow = [dictionary.doc2bow(text) for text in tokenize_buf]\n",
    "#     que_vec = [item for itemList in doc_bow for item in itemList]\n",
    "#     topic_vec = ldamodel[que_vec]\n",
    "\n",
    "#     word_count_array = np.empty((len(topic_vec), 2), dtype = np.object)\n",
    "#     for i in range(len(topic_vec)):\n",
    "#         word_count_array[i, 0] = topic_vec[i][0]\n",
    "#         word_count_array[i, 1] = topic_vec[i][1]\n",
    "\n",
    "#     idx = np.argsort(word_count_array[:, 1])\n",
    "#     idx = idx[::-1]\n",
    "#     word_count_array = word_count_array[idx]\n",
    "\n",
    "#     final = []\n",
    "#     final = ldamodel.print_topic(word_count_array[0, 0], len(word_count_array))#1)\n",
    "\n",
    "#     question_topic = final.split('*') ## as format is like \"probability * topic\"\n",
    "#     return question_topic\n",
    "#     #return question_topic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#texts = tokenize_doc(doc_set)\n",
    "test_LDA_buf = test_buf.tolist()\n",
    "doc_set = test_LDA_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229451"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataFrame_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_piece = round(len(doc_set)/len(df_stack_dupExc))\n",
    "sub_doc_set = []\n",
    "for piece in range(num_piece):\n",
    "#    print(\"piece:\"+str(piece))\n",
    "    if num_piece<=8:\n",
    "        sub_piece = doc_set[((piece)*len(df_stack_dupExc)+1):(piece+1)*len(df_stack_dupExc)]\n",
    "#         print(\"len:\"+str(len(sub_piece)))\n",
    "#         print(\"****from:\"+str((piece)*len(df_stack_dupExc)))\n",
    "#         print(\"to:\"+str((piece+1)*len(df_stack_dupExc)))\n",
    "        sub_doc_set = sub_doc_set + [sub_piece]\n",
    "    else:\n",
    "        sub_piece = doc_set[((piece)*len(df_stack_dupExc)+1):]\n",
    "#         print(\"len:\"+str(len(sub_piece)))\n",
    "#         print(\"****from:\"+str((piece)*len(df_stack_dupExc)))\n",
    "#         print(\"to:\"+str((piece+1)*len(df_stack_dupExc)))\n",
    "        sub_doc_set = sub_doc_set + [sub_piece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Should I have a hair transplant at age 24  How much would it cost ',\n",
       " 'What but is the best way to send money from China to the US ',\n",
       " 'Which food not emulsifiers ',\n",
       " 'How \"aberystwyth\" start reading ',\n",
       " 'How are the two wheeler insurance from Bharti Axa insurance ',\n",
       " 'How can I reduce my belly fat through a diet ',\n",
       " 'By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money ',\n",
       " 'What are the how best books of all time ',\n",
       " 'After 12th years old boy and I had sex with a 12 years old girl, with her consent. Is there anything wrong ',\n",
       " 'What is the best slideshow app for Android ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sub_doc_set))\n",
    "sub_doc_set[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n",
      "aed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4163e2085fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_doc_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_take\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtoken_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpkl_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'token_piece'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtoken_ind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token_piece.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# selfref_list = [1, 2, 3]\n",
    "# selfref_list.append(selfref_list)\n",
    "for sub_take in range(len(sub_doc_set)):\n",
    "    texts = tokenize_doc(sub_doc_set[sub_take])\n",
    "    token_ind = sub_take\n",
    "    pkl_path = '../../Data/token_piece'+str(token_ind)+'.pkl'\n",
    "    output = open(pkl_path, 'wb')\n",
    "    if num_piece<=8:\n",
    "        range_df = [((token_ind)*len(df_stack_dupExc)+1),(token_ind+1)*len(df_stack_dupExc)]\n",
    "    else:\n",
    "        range_df = [((token_ind)*len(df_stack_dupExc)+1),len(df_stack_dupExc)] \n",
    "    save_dataFrame = dataFrame_buf.iloc[range_df[0]:range_df[1]]\n",
    "    dict_buf = {\"range_df_stack\": range_df,\n",
    "            \"data_df\": save_dataFrame,\n",
    "            \"tokenize_data\": texts}\n",
    "# Pickle dictionary using protocol 0.\n",
    "    pickle.dump(dict_buf, output)\n",
    "\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(selfref_list, output, -1)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
